#language anatomy

\use{\load{concourse/docs}}

\template{\load{concourse/docs-template}}

\title{Versioned S3 Artifacts}{versioned-s3-artifacts}

\literate-segment{
  This document will guide you through a pipeline modeled on a fairly common
  real-world use case of pushing tested, built artifacts into S3 buckets.

  The end-to-end scenario is to monitor a Git repository for commits, and when
  new commits are detected, run its unit tests.

  If the unit tests pass, the pipeline will then create a new release candidate
  artifact with automated versioning, which then will be placed in a S3 bucket.

  From there, the pipeline will run integration tests against the release
  candidate, and if those pass, it will create a final artifact and "ship it" by
  putting it in a different S3 bucket.

  The resulting pipeline will look like this:

  \pipeline-image{tutorials/versioned-s3-artifacts.svg}
}

\literate-segment{
  First, we'll define our resources. These are the \italic{objects} used in
  our pipeline. The \code{resources} configuration simply enumerates each
  of their locations.
}{
  \codeblock{yaml}{
    resources:
  }
}

\literate-segment{
  Our first resource will be the location of our product's source code.
  Let's pretend it lives in a Git repo, and so we'll use the
  \hyperlink{https://github.com/concourse/git-resource}{\code{git}
  resource type}.

  The \code{git} resource type requires two source parameters: \code{uri}
  and \code{branch}. We're using a SSH URI, so we'll also need to specify
  \code{private_key}.

  To avoid embedding credentials in the pipeline config, we'll use
  a \reference{parameters}{parameter}.
}{
  \codeblock{yaml}{
    - name: my-product
      type: git
      source:
        uri: git@github.com:my-user/my-product.git
        branch: master
        private_key: ((my-product-github-private-key))
  }
}

\literate-segment{
  We'll need a resource to represent the semantic version of our product,
  which we'll use to generate release candidates, and bump every time we
  ship. For this we'll use the
  \hyperlink{https://github.com/concourse/semver-resource}{\code{semver}
  resource type}.

  Currently, \code{semver} resources keep track of the version as a file
  in a S3 bucket, so we'll need to specify the credentials for the bucket,
  and a name for the file.

  If your product already has a version number, you can specify it as
  \code{initial_version}. If not specified, the version will start as
  \code{0.0.0}.
}{
  \codeblock{yaml}{
    - name: version
      type: semver
      source:
        bucket: my-product-pipeline-artifacts
        key: current-version
        access_key_id: ((s3-access-key-id))
        secret_access_key: ((s3-secret-access-key))
        initial_version: 1.0.0
  }
}

\literate-segment{
  Let's define the resource for storing our product's release candidate
  artifacts generated by the pipeline. This is done with the
  \hyperlink{https://github.com/concourse/s3-resource}{\code{s3}
  resource type}.

  The \code{s3} resource type is minimally configured with a \code{bucket}
  name and a \code{regexp}, which will be used to match files in the
  bucket and order them by the version number extracted by the first
  capture group.

  Since we'll be writing objects into this bucket, we'll need to configure
  it with AWS credentials.
}{
  \codeblock{yaml}{
    - name: my-product-rc
      type: s3
      source:
        bucket: my-product-pipeline-artifacts
        regexp: my-product-(.*).tgz
        access_key_id: ((s3-access-key-id))
        secret_access_key: ((s3-secret-access-key))
  }
}

\literate-segment{
  We'll need one more \code{s3} resource to represent shipped artifacts.
}{
  \codeblock{yaml}{
    - name: my-product-final
      type: s3
      source:
        bucket: my-product
        regexp: my-product-(.*).tgz
        access_key_id: ((s3-access-key-id))
        secret_access_key: ((s3-secret-access-key))
  }
}

\literate-segment{
  Now that we've got all our resources defined, let's move on define the
  \italic{functions} to apply to them, as represented by \code{jobs}
}{
  \codeblock{yaml}{
    jobs:
  }
}

\literate-segment{
  Our first job will run the unit tests for our project. This job will
  fetch the source code, using the \reference{get-step} step with the
  \code{my-product} resource, and execute the
  \reference{configuring-tasks}{Task configuration file} living in the
  repo under \code{ci/unit.yml} using a \reference{task-step} step.

  We set \code{trigger: true} on the \reference{get-step} step so that it
  automatically triggers a new \code{unit} build whenever new commits are
  pushed to the \code{my-product} repository.
}{
  \codeblock{yaml}{
    - name: unit
      plan:
      - get: my-product
        trigger: true
      - task: unit
        file: my-product/ci/unit.yml
  }
}

\literate-segment{
  Our pipeline now does something! But we're not quite delivering
  artifacts yet.
}

\literate-segment{
  Let's consider anything making it past the unit tests to be a candidate
  for a new version to ship. We'll call the job that builds candidate
  artifacts \code{build-rc}.

  Because this job makes modifications to our product version, we'll want to
  make sure it doesn't run concurrently with anything else doing the same
  thing. Otherwise we may generate versions or release candidates out of order.

  This is done by specifying \reference{serial_groups}, which is a list of
  arbitrary tags. We'll make sure to list the same tags in the other jobs which
  modify the version.
}{
  \codeblock{yaml}{
    - name: build-rc
      serial_groups: [version]
      plan:
  }
}

\literate-segment{
  First, let's be sure to only grab versions of \code{my-product} that
  have passed unit tests. Let's have new occurrences of these versions
  also trigger new builds, while we're at it.
}{
  \codeblock{yaml}{
    {}  - get: my-product
    {}    passed: [unit]
    {}    trigger: true
  }
}

\literate-segment{
  We'll also need a new release candidate version number. For this, the
  \hyperlink{https://github.com/concourse/semver-resource}{\code{semver}}
  resource type can be used to generate versions by specifying params in
  the \reference{get-step} step.

  Specifying \code{pre: rc} makes it so that if the current version is e.g.
  \code{1.2.3-rc.3}, we'll get \code{1.2.3-rc.4}.
}{
  \codeblock{yaml}{
    {}  - get: version
    {}    params: \{pre: rc\}
  }
}

\literate-segment{
  Now, we'll execute our \code{build-artifact} task configuration, which
  we'll assume has two inputs (\code{my-product} and \code{version}) and
  produces a file named \code{my-product-{VERSION}.tgz} in an output called
  \code{built-artifact} when executed.
}{
  \codeblock{yaml}{
    {}  - task: build-artifact
    {}    file: my-product/ci/build-artifact.yml
  }
}

\literate-segment{
  Now that we have a tarball built, let's \reference{put-step} it up to the
  pipeline artifacts S3 bucket via the \code{my-product-rc} resource
  defined above.

  Note that we refer to the task that generated the \code{.tgz} in the
  path specified by the \code{from} param.
}{
  \codeblock{yaml}{
    {}  - put: my-product-rc
    {}    params: \{file: built-artifact/my-product-*.tgz\}
  }
}

\literate-segment{
  We'll also need to push up the newly bumped version number, so that next
  time we bump it'll be based on this new one.

  Note that the \code{file} param points at the version created by the
  \code{version} step above.
}{
  \codeblock{yaml}{
    {}  - put: version
    {}    params: \{file: version/number\}
  }
}

\literate-segment{
  Now we're cooking with gas. But still, we haven't shipped any actual
  versions of the project yet: only candidates! Let's move on to the later
  stages in the pipeline.
}

\literate-segment{
  Let's assume there's some more resource-intensive integration suite that
  uses our product, as a black-box. This will be the final set of checks
  and balances before shipping actual versions.

  Let's assume this suite has to talk to some external environment, and so
  we'll configure the job with \code{serial: true} here to prevent
  concurrent builds from polluting each other.
}{
  \codeblock{yaml}{
    - name: integration
      serial: true
      plan:
  }
}

\literate-segment{
  For the integration job, we'll need two things: the candidate artifact,
  and the repo that it came from, which contains all our CI scripts.

  Note that this usage of \code{passed} guarantees that the two versions
  of \code{my-product} and \code{my-product-rc} respectively came out from
  the \italic{same build} of \code{build-rc}. See \reference{get-step} for more
  information.
}{
  \codeblock{yaml}{
    {}  - get: my-product-rc
    {}    trigger: true
    {}    passed: [build-rc]
    {}  - get: my-product
    {}    passed: [build-rc]
  }
}

\literate-segment{
  We'll now run the actual integration task. Since it has to talk to some
  external environment, we'll use \code{params} to forward its
  credentials along to the task. See \reference{task-step} for more
  information.

  Again we'll use \reference{parameters}{parameters} in the config file to
  prevent hardcoding them.
}{
  \codeblock{yaml}{
    {}  - task: integration
    {}    file: my-product/ci/integration.yml
    {}    params:
    {}      API_ENDPOINT: ((integration-api-endpoint))
    {}      ACCESS_KEY: ((integration-access-key))
  }
}

\literate-segment{
  At this point in the pipeline we have artifacts that we're ready to
  ship. So let's define a job that, when manually triggered, takes the
  latest candidate release artifact and publishes it to the S3 bucket
  containing our shipped product versions.
}

\literate-segment{
  We'll call the job \code{shipit}. Since it'll also be modifying the version,
  we'll place it in the same serial group we specified for \code{build-rc}.
}{
  \codeblock{yaml}{
    - name: shipit
      serial_groups: [version]
      plan:
  }
}

\literate-segment{
  Similar to the \code{integration} job, we'll once again need both our
  source code and the latest release candidate, this time having passed
  \code{integration} together.

  Note that we have not specified \code{trigger: true} this time - this is
  because with a typical release-candidate pipeline, the shipping stage is
  only ever manually kicked off.
}{
  \codeblock{yaml}{
    {}  - get: my-product-rc
    {}    passed: [integration]
    {}  - get: my-product
    {}    passed: [integration]
  }
}

\literate-segment{
  Now we'll need to determine the final version number that we're about to
  ship. This is once again done by specifying \code{params} when fetching
  the version.

  This time, we'll only specify \code{bump} as \code{final}. This means
  "take the version number and chop off the release candidate bit."
}{
  \codeblock{yaml}{
    {}  - get: version
    {}    params: \{bump: final\}
  }
}

\literate-segment{
  Next, we'll need to convert the release candidate artifact to a final
  version.

  This step depends on the type of product you have; in the simplest case
  it's just a matter of renaming the file, but you may also have to
  rebuild it with the new version number, or push dependent files, etc.

  For the purposes of this example, let's assume we have a magical task that
  does it all for us, and leaves us with a file called
  \code{my-product-{VERSION}.tgz} in a \code{built-product} output, just as
  with the \code{build-rc} job before.
}{
  \codeblock{yaml}{
    {}  - task: promote-to-final
    {}    file: my-product/ci/promote-to-final.yml
  }
}

\literate-segment{
  And now for the actual shipping!
}{
  \codeblock{yaml}{
    {}  - put: my-product-final
    {}    params: \{file: built-product/my-product-*.tgz\}
    {}  - put: version
    {}    params: \{file: version/number\}
  }
}

\literate-segment{
  This is all well and good, but you may have noticed it's only good for shipping
  one version. We only ever go from release candidates to final versions, and
  never do any actual version bumps!

  Bumping your product's version is very much a human decision, so for this
  example we'll just assume the product manager will come in and decide what the
  next version should be at some point.

  The simplest way to implement this is to have three jobs: one for doing a major
  bump, one for doing a minor bump, and one for doing a patch bump. These three
  jobs will do both the bump itself, and immediately bump to \code{-rc.1} of the
  new version. This is done by specifying both \code{bump} and \code{pre} params.
}

\literate-segment{
  The \code{major} job simply has a \reference{put-step} for bumping the
  version in-place. Because it's modifying the version, we'll use
  \reference{serial_groups} to ensure it doesn't run concurrently with
  \code{build-rc}, \code{shipit}, and the other bump jobs.
}{
  \codeblock{yaml}{
    - name: major
      serial_groups: [version]
      plan:
      - put: version
        params: \{bump: major, pre: rc\}
  }
}

\literate-segment{
  The \code{minor} job is basically the same, but with \code{bump: minor}
  instead, unsurprisingly.
}{
  \codeblock{yaml}{
    - name: minor
      serial_groups: [version]
      plan:
      - put: version
        params: \{bump: minor, pre: rc\}
  }
}

\literate-segment{
  The \code{patch} job will follow the same approach, but with one twist: we
  want to immediately bump to the next patchlevel release candidate after
  shipping.

  This is so the pipeline can start generating candidates for a new version
  without requiring the product manager to decide the version to target next.
  We do a \code{patch} bump just because it's the most conservative bump we can
  make for the next release before knowing what'll be in it.

  We'll have the \code{patch} job auto-trigger by having a dummy \code{get}
  action that depends on something having made it through the \code{shipit}
  job, with \code{trigger: true}. We'll use the \code{version} resource for
  this since it's the smallest thing coming out of the \code{shipit} job.
}{
  \codeblock{yaml}{
    - name: patch
      serial_groups: [version]
      plan:
      - get: version
        passed: [shipit]
        trigger: true
      - put: version
        params: \{bump: patch, pre: rc\}
  }
}
